---
title: A Quick Intro to Robust Bayesian Models via Conditioning on Insufficient Statistics
author: John Lewis
date: '2017-05-28'
slug: a-quick-intro-to-robust-bayesian-models-via-conditioning-on-insufficient-statistics
categories:
  - restricted likelihood
  - brlm
  - R
tags:
  - restricted likelihood
  - brlm
  - R
---



<p>Conditioning on robust summaries of the data in a Bayesian model is one way to achieve robustness to model miss-specification. I have called this the “restricted likelihood” <a href="http://www.stat.osu.edu/~yklee/mss/tr878.pdf">here</a> and <a href="https://etd.ohiolink.edu/!etd.send_file?accession=osu1407505392&amp;disposition=inline">here</a> since the full data likelihood is replaced with the likelihood conditioned on only the robust summary (i.e. a restricted likelihood).</p>
<p>One of the easiest examples to conceptualize is outliers in a univariate setting. Suppose the true data generating mechanism is a contaminated normal:</p>
<p><span class="math display">\[y_1, y_2, \dots, y_n \sim (1-p)N(\mu, \sigma^2) + pN(\mu, c\sigma^2)\]</span></p>
<p>with <span class="math inline">\(c&gt;1\)</span> and we are interested in estimating <span class="math inline">\(\mu\)</span>. Since we don’t know the data generating mechanism exactly we just decide to fit the simple normal Bayesian model:</p>
<p><span class="math display">\[\mu \sim N(\eta, \tau^2),\]</span></p>
<p><span class="math display">\[\sigma^2\sim IG(\alpha, \beta),\]</span></p>
<p><span class="math display">\[y_1, y_2, \dots, y_n \sim N(\mu, \sigma^2)\]</span></p>
<p>Of course each data point gives information about <span class="math inline">\(\mu\)</span> but the data coming from the contamination component gives less information about <span class="math inline">\(\mu\)</span>. Since we are fitting the wrong model it’s probably not good to treat these data points the same. In robust statistics, estimators like the median, trimmed-mean, or M-estimators down-weight outliers in a more or less automatic sense. In an analogous fashion, a Bayesian could condition on these robust summaries instead of the entire data set <span class="math inline">\(Y=(y_1, y_2, \dots, y_n)\)</span>. Though we have developed fitting methods to condition on such statistics (see above links to papers), for this post let’s condition on a middling set of order statistics <span class="math inline">\(T(Y)=(y_{(k)},y_{(k+1)},\dots, y_{(n-k)})\)</span>. The reasons being are 1) this is one of the first things I tried when starting to think about these problems and 2) the model is easy to fit since the pdf of a set of order statistics is analytically tractable (i.e. the restricted likelihood). This is not the case for many robust statistics like M-estimators).</p>
<p>The full posterior (conditioning on the full data) is <span class="math inline">\(\pi(\theta|Y)\propto \pi(\theta)f(Y|\theta)\)</span> with <span class="math inline">\(\theta = (\mu, \sigma^2)\)</span> while the “restricted posterior” is <span class="math inline">\(\pi(\theta|T(Y))\propto \pi(\theta)f(T(Y)|\theta)\)</span> with <span class="math inline">\(f(T(Y)|\theta)\)</span> just the pdf of the set of order-statistics. The function <a href="https://github.com/jrlewi/brlm/blob/master/R/fitOrderStat.R"><code>fitOrderStatistics</code></a> in the (still developing) <a href="https://github.com/jrlewi/brlm"><code>brlm</code></a> package can be used to fit both of these models on a grid.</p>
<div id="demonstration" class="section level1">
<h1>Demonstration</h1>
<p>Let’s load the required packages and generate some data from the contaminated distribution:</p>
<pre class="r"><code>library(reshape2)
library(tidyverse)</code></pre>
<pre><code>## Loading tidyverse: ggplot2
## Loading tidyverse: tibble
## Loading tidyverse: tidyr
## Loading tidyverse: readr
## Loading tidyverse: purrr
## Loading tidyverse: dplyr</code></pre>
<pre><code>## Conflicts with tidy packages ----------------------------------------------</code></pre>
<pre><code>## filter(): dplyr, stats
## lag():    dplyr, stats</code></pre>
<pre class="r"><code>library(RColorBrewer)
#library(devtools); install_github(&quot;jrlewi/brlm&quot;) if needed. brlm=Bayesian Restricted Likelihood Methods.
library(brlm)


plotCors &lt;- brewer.pal(9, &#39;Set1&#39;) #plot colors
#function to generated the contaminated data
gen_data &lt;- function(n,mu, sigma, p, c){
  out &lt;- rbinom(n, 1, p)
  sapply(out, function(ot) ifelse(ot, rnorm(1,mu, sqrt(c)*sigma), rnorm(1,mu, sigma)))
}

set.seed(8675309) #the Jenny seed :)

n &lt;- 100
mu &lt;-0
sigma &lt;-1
p &lt;- .2
c &lt;- 10
y &lt;- gen_data(n,mu, sigma, p, c)
ggplot(as_tibble(y), aes(x = value)) + geom_histogram(col = 1, fill = plotCors[2])</code></pre>
<pre><code>## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`.</code></pre>
<p><img src="/post/2017-05-28-a-quick-intro-to-robust-bayesian-models-via-conditioning-on-insufficient-statistics_files/figure-html/gen%20data-1.png" width="672" /></p>
<p>Now we can fit the models. The parameter <code>k</code> specifies the set of middling order statistics. Setting <code>k=0</code> fits the full normal model.</p>
<pre class="r"><code>mu_lims &lt;- c(mu - sigma, mu + sigma) # play around with these since we are fitting on a grid. Just need to make sure grid covers support of non-zero posterior mass - MCMC would avoid this :) 
length_mu &lt;- 100
sigma2_lims &lt;- c(.1, 5)
length_sigma2 &lt;- 100

# fixed prior parameters
eta &lt;- 2; tau &lt;- 10; alpha &lt;- 5; beta &lt;- 5
k &lt;- floor(.1*n)


fitFull &lt;- fitOrderStat(y,k=0, mu_lims,length_mu, sigma2_lims,length_sigma2, eta, tau, alpha, beta)

fitRest &lt;- fitOrderStat(y,k=k, mu_lims,length_mu, sigma2_lims,length_sigma2, eta, tau, alpha, beta)

post_mu &lt;- tibble(mu = fitRest$muPost[,1], restricted = fitRest$muPost[, 2], full = fitFull$muPost[,2])
post_mu &lt;- melt(post_mu, id.vars = c(&#39;mu&#39;), variable.name = &#39;posterior&#39;)

post_sigma2 &lt;- tibble(sigma2 = fitRest$sigma2Post[,1], restricted = fitRest$sigma2Post[, 2], full = fitFull$sigma2Post[,2])
post_sigma2 &lt;- melt(post_sigma2 , id.vars = c(&#39;sigma2&#39;), variable.name = &#39;posterior&#39;)


(p_post_mu &lt;- ggplot(post_mu, aes(x = mu, y = value,  col = posterior)) + geom_line() +
  geom_vline(xintercept = mu, lty = 2) +
    xlim(c(mu - sigma, mu + sigma)))</code></pre>
<p><img src="/post/2017-05-28-a-quick-intro-to-robust-bayesian-models-via-conditioning-on-insufficient-statistics_files/figure-html/fit%20models-1.png" width="672" /></p>
<pre class="r"><code>(p_post_sigma2 &lt;- ggplot(post_sigma2, aes(x = sigma2, y = value,  col = posterior)) + 
    geom_line() +
    geom_vline(xintercept = sigma^2, lty = 2) +
    xlim(c(0, 5)))</code></pre>
<p><img src="/post/2017-05-28-a-quick-intro-to-robust-bayesian-models-via-conditioning-on-insufficient-statistics_files/figure-html/fit%20models-2.png" width="672" /></p>
<p>We see the posterior for <span class="math inline">\(\mu\)</span> under the restricted posterior is more precise. This is related to the fact that estimation of <span class="math inline">\(\sigma^2\)</span> is also improved under the restricted posterior.</p>
<p>Now suppose that the full model gets the likelihood correct - that is, the data are generated from a single normal:</p>
<pre class="r"><code>set.seed(123)
y &lt;- rnorm(n, mu, sigma)

fitFull_n &lt;- fitOrderStat(y,k=0, mu_lims,length_mu, sigma2_lims,length_sigma2, eta, tau, alpha, beta)

fitRest_n &lt;- fitOrderStat(y,k=k, mu_lims,length_mu, sigma2_lims,length_sigma2, eta, tau, alpha, beta)

post_mu_n &lt;- tibble(mu = fitRest_n$muPost[,1], restricted = fitRest_n$muPost[, 2], full = fitFull_n$muPost[,2])
post_mu_n &lt;- melt(post_mu_n, id.vars = c(&#39;mu&#39;), variable.name = &#39;posterior&#39;)

post_sigma2_n &lt;- tibble(sigma2 = fitRest_n$sigma2Post[,1], restricted = fitRest_n$sigma2Post[, 2], full = fitFull_n$sigma2Post[,2])
post_sigma2_n &lt;- melt(post_sigma2_n , id.vars = c(&#39;sigma2&#39;), variable.name = &#39;posterior&#39;)


(p_post_mu_n &lt;- ggplot(post_mu_n, aes(x = mu, y = value,  col = posterior)) + geom_line() +
  geom_vline(xintercept = mu, lty = 2) +
    xlim(c(mu - sigma, mu + sigma)))</code></pre>
<p><img src="/post/2017-05-28-a-quick-intro-to-robust-bayesian-models-via-conditioning-on-insufficient-statistics_files/figure-html/normal%20data-1.png" width="672" /></p>
<pre class="r"><code>(p_post_sigma2_n &lt;- ggplot(post_sigma2_n, aes(x = sigma2, y = value,  col = posterior)) + 
    geom_line() +
    geom_vline(xintercept = sigma^2, lty = 2) +
    xlim(c(0, 5)))</code></pre>
<p><img src="/post/2017-05-28-a-quick-intro-to-robust-bayesian-models-via-conditioning-on-insufficient-statistics_files/figure-html/normal%20data-2.png" width="672" /></p>
<p>In this case - inference is essentially identical using either the restricted or full model - an often desired property of robust models.</p>
</div>
<div id="simulation" class="section level1">
<h1>Simulation</h1>
<p>It’s probably best to re-do the analysis over several data sets. Here we generate 100 data sets from the contaminated model, fit the full and restricted posteriors, and summarize the posterior means. We’ll also try some parallelization using <code>foreach</code>.</p>
<pre class="r"><code>library(doParallel)</code></pre>
<pre><code>## Loading required package: foreach</code></pre>
<pre><code>## 
## Attaching package: &#39;foreach&#39;</code></pre>
<pre><code>## The following objects are masked from &#39;package:purrr&#39;:
## 
##     accumulate, when</code></pre>
<pre><code>## Loading required package: iterators</code></pre>
<pre><code>## Loading required package: parallel</code></pre>
<pre class="r"><code>cl &lt;- makeCluster(detectCores())
registerDoParallel(cl)
n_sims &lt;- 100
(tm &lt;- system.time({
result &lt;- foreach(i = 1:n_sims, .combine = rbind, .packages = &#39;brlm&#39;) %dopar% {
y &lt;- gen_data(n,mu, sigma, p, c)
fitFull &lt;- fitOrderStat(y,k=0, mu_lims,length_mu, sigma2_lims,length_sigma2, eta, tau, alpha, beta)
fitRest &lt;- fitOrderStat(y,k=k, mu_lims,length_mu, sigma2_lims,length_sigma2, eta, tau, alpha, beta)  
c(fitFull$postMeans[1], fitRest$postMeans[1])
}
})[3])
registerDoSEQ()

result &lt;- tibble(full = result[,1], restricted = result[,2])
result &lt;- reshape2::melt(result, variable.name = &#39;posterior&#39;, value.name = &#39;mean mu&#39;)</code></pre>
<pre><code>## No id variables; using all as measure variables</code></pre>
<pre class="r"><code>(g_sim &lt;- ggplot(result, aes(y = `mean mu`, x = posterior, fill = posterior)) + geom_boxplot())</code></pre>
<p><img src="/post/2017-05-28-a-quick-intro-to-robust-bayesian-models-via-conditioning-on-insufficient-statistics_files/figure-html/simulation-1.png" width="672" /></p>
<pre><code>## elapsed 
##   97.71</code></pre>
<p>The means of the posterior means are roughly equal with smaller variance under the restricted posterior. The raw numbers are:</p>
<pre class="r"><code>(sumry &lt;- as.data.frame(result) %&gt;% group_by(posterior) %&gt;% dplyr::summarise(mean = mean(`mean mu`), sd=sd(`mean mu`)))</code></pre>
<pre><code>## # A tibble: 2 x 3
##    posterior        mean        sd
##       &lt;fctr&gt;       &lt;dbl&gt;     &lt;dbl&gt;
## 1       full 0.007373827 0.1488590
## 2 restricted 0.016813200 0.1263784</code></pre>
<p>We see a reduction in standard deviation of roughly 15.1<span class="math inline">\(\%\)</span> under the restricted posterior.</p>
</div>
<div id="summary" class="section level1">
<h1>Summary</h1>
<p>This was just a brief intro to the ideas and potential advantages of restricted likelihood methods. Conditioning on order statistics is conceptually simple and easy to implement since the pdf of order statistics is known. The choice of which order statistics to condition on is up for discussion. I have also developed MCMC methods to condition on M-estimators in regression settings (see <a href="http://www.stat.osu.edu/~yklee/mss/tr878.pdf">this</a> or <a href="https://etd.ohiolink.edu/!etd.send_file?accession=osu1407505392&amp;disposition=inline">this</a>). Implementation in this settings is more difficult since the likelihood conditioned on such estimators is intractable. Code implementing some of these methods can be found <a href="https://github.com/jrlewi/brlm">here</a> or <a href="https://github.com/jrlewi/brlmPaperCode">here</a>.</p>
</div>
